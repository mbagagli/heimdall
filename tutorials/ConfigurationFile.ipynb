{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f1e7987-314f-4ab3-a7d3-3667fec2309d",
   "metadata": {},
   "source": [
    "# HEIMDALL's configuration file\n",
    "\n",
    "This notebook cover the definitions and description of the inputs parameters\n",
    "\n",
    "__version__:  0.3.0\n",
    "\n",
    "**NB:** the version reported in the YAML file must match the one installed.\n",
    "\n",
    "--------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cd01d8-2be9-4965-9fe9-873d3927099a",
   "metadata": {},
   "source": [
    "Here's the configuration file's template:\n",
    "\n",
    "```yaml\n",
    "version: \"0.3.0\"\n",
    "\n",
    "# :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
    "# :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
    "\n",
    "BUILD_GNN:\n",
    "  PROJ_START_DATE: \"2000-01-01T00:00:00\"\n",
    "  PROJ_END_DATE: \"2050-12-31T23:59:59\"\n",
    "  INVENTORY_PATH: \"Inventory_training_data.xml\"\n",
    "  NETWORKS: [\"N\", ]  # Network code selection of stations (if False or null, select ALL network codes in Inventory)\n",
    "  PLOT_GRAPH_ARCH: True\n",
    "  BASE_CONNECT_TYPE: \"KNN\"\n",
    "  BASE_CONNECT_VALUE: 7  # degree\n",
    "  SELF_LOOPS: True\n",
    "  SCALE_DISTANCES: \"max\"   # Also NONE or FALSE or STD\n",
    "  GNN_TAG: \"heimdall_graph\"  # stored inside the NPZ\n",
    "  PLOT_BOUNDARIES: []\n",
    "\n",
    "BUILD_GRID:\n",
    "  BOUNDARIES: [130.3, 131.8,\n",
    "               32.55, 33.5,\n",
    "               0.0, 25.0]       # km\n",
    "  SPACING_XYZ: [0.25, 0.25, 0.1]  # km\n",
    "  CENTRE: False\n",
    "  GRID_TAG: \"heimdall_grid\"  # stored in the NPZ\n",
    "\n",
    "# :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
    "# :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
    "\n",
    "PREPARE_DATA:\n",
    "  DOWNSAMPLE:\n",
    "    new_df: 100.0\n",
    "    hp_freq: 2   # The bandpass filter will be applied from HP-FREQ to the antialias frequency ALWAYS\n",
    "\n",
    "  SOURCE_ERRORS_BY_PICKS:\n",
    "    # n.picks in window:  [radius (km), max background noise, source noise]\n",
    "    0:  [0.0, 0.0, 0.0]\n",
    "    1:  [0.0, 0.0, 0.0]\n",
    "    2:  [0.0, 0.0, 0.0]\n",
    "    3:  [7.0, 0.0, 0.0]\n",
    "    4:  [6.0, 0.0, 0.0]\n",
    "    5:  [5.0, 0.0, 0.0]\n",
    "    6:  [4.0, 0.0, 0.0]\n",
    "    7:  [3.0, 0.0, 0.0]\n",
    "    8:  [2.0, 0.0, 0.0]\n",
    "    9:  [1.0, 0.0, 0.0]\n",
    "    10: [0.7, 0.0, 0.0]\n",
    "    11: [0.5, 0.0, 0.0]\n",
    "    # higher number of picks in windows will keep the last key\n",
    "\n",
    "  SLICING:\n",
    "      wlen_seconds: 5.0\n",
    "      slide_seconds: 0.5\n",
    "\n",
    "# :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
    "# :::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::\n",
    "\n",
    "TRAINING_PARAMETERS:\n",
    "  # ----------  output\n",
    "  PLOTS:\n",
    "    make_plots:       True      # if False the code never calls gplt\n",
    "    every_batches:    50        # produce a figure every N batches\n",
    "\n",
    "  # ----------  data sampling & augmentations\n",
    "  DATASET:\n",
    "    how_many:         null      # null == use all events\n",
    "    evenize:                    # arguments passed to __evenize_classes__\n",
    "      min_pick_signal:  1\n",
    "      reduce_data:      False\n",
    "      noise_perc:       0.10\n",
    "      signal_perc:      0.90\n",
    "    batch_size: 8\n",
    "    n_work: 5\n",
    "\n",
    "  AUGMENTATION:\n",
    "    enabled:          True\n",
    "\n",
    "  RANDOM_SEED:        42\n",
    "\n",
    "  # ----------  splits\n",
    "  SPLIT:\n",
    "    test:             0.10\n",
    "    val:              0.10\n",
    "\n",
    "  # ----------  optimiser & scheduler\n",
    "  OPTIMISATION:\n",
    "    learning_rate:    1.e-4\n",
    "    epochs:           null      # null --> use early stopping (next block)\n",
    "    early_stopping:\n",
    "      patience:       7\n",
    "      delta:          1.e-4\n",
    "\n",
    "  # ----------  loss weighting\n",
    "  LOCATOR_LOSS:          # W1_XY, W2_XZ, W3_YZ\n",
    "    xy:   1.0\n",
    "    xz:   1.0\n",
    "    yz:   1.0\n",
    "\n",
    "  COMPOSITE_LOSS:        # ALPHA, BETA, GAMMA\n",
    "    alpha: 1.0\n",
    "    beta:  1.0\n",
    "    gamma: 1.0\n",
    "\n",
    "  # ----------  model initialisation\n",
    "  MODEL:\n",
    "    pretrained_weights: \"\"      # path to previously trained model (i.e. transfer learning or fine tuning of the heads) or \"\" to train from scratch\n",
    "    freeze_encoder:    False    # keep it False unless you've good reasons not to ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991f302b-fd6e-40ae-84ef-7d47b68f4f44",
   "metadata": {},
   "source": [
    "---------------------------------------------------------\n",
    "\n",
    "To start with, inside the whole framework, the configuration files will be read with the `heimdall.io.read_configuration_file` function, and will return an `AttributeDict` syle dictionary: therefore it can be accessed using the dot sintax (i.e. `config.version` or `config.TRAINING_PARAMETERS.MODEL.freeze_encoder`).\n",
    "\n",
    "Below is a **plain‑text description in Markdown** of every section and parameter found in `heimdall_v030_confs.yml`.  \n",
    "For each key you’ll see:\n",
    "\n",
    "* **Type** – accepted value(s) or data‑type.  \n",
    "* **Default / Example** – the value shown in your file.  \n",
    "* **Purpose** – what the code uses it for.\n",
    "\n",
    "---\n",
    "\n",
    "## Version\n",
    "\n",
    "| Key | Type | Default / Example | Purpose |\n",
    "|---|---|---|---|\n",
    "| `version` | string (semantic) | '0.3.0' | Internal schema version; the loader checks this before parsing the file. |\n",
    "\n",
    "---\n",
    "\n",
    "## BUILD_GNN — graph‑building options\n",
    "\n",
    "| Key | Type | Default / Example | Purpose |\n",
    "|---|---|---|---|\n",
    "| `PROJ_START_DATE` | ISO‑8601 datetime | '2000‑01‑01T00:00:00' | First timestamp of data to include when scanning waveform archives. |\n",
    "| `PROJ_END_DATE` | ISO‑8601 datetime | '2050‑12‑31T23:59:59' | Last timestamp to include. |\n",
    "| `INVENTORY_PATH` | path / string | 'Inventory_training_data.xml' | StationXML (or similar) inventory used to fetch station coordinates (nodes) & metadata. |\n",
    "| `NETWORKS` | list of strings or **null** | ['N'] | Network codes to keep (e.g. 'IU', 'XR'). Empty/null -> keep all networks. |\n",
    "| `PLOT_GRAPH_ARCH` | bool | True | If True, write a PNG/PDF visualisation of the final graph. |\n",
    "| `BASE_CONNECT_TYPE` | 'KNN', 'DIST', … | 'KNN' | Strategy to connect stations.  **KNN** - each node linked to `BASE_CONNECT_VALUE` nearest neighbours. **DBSCAN** Use radius‑based. |\n",
    "| `BASE_CONNECT_VALUE` | int | 7 | Degree for the chosen BASE_CONNECT_TYPE (e.g. *k* in k‑NN, km radius if **DBSCAN** used). |\n",
    "| `SELF_LOOPS` | bool | True | Add self‑edges so convolution layers can mix a node’s own features. |\n",
    "| `SCALE_DISTANCES` | 'max', 'std', 'none'/false | 'max' | How to normalise edge‑length attributes: <br>• **max** → divide by max distance. <br>• **std** → z‑score. <br>• **none/false** → leave raw kilometres. |\n",
    "| `GNN_TAG` | string | 'heimdall_graph' | Name stored inside the .npz graph file (useful when several graphs sit in the same archive). |\n",
    "| `PLOT_BOUNDARIES` | list [lon₁, lon₂, lat₁, lat₂] | [] (empty) | Geographic map bounds for plots; empty → auto‑fit to stations. |\n",
    "\n",
    "---\n",
    "\n",
    "## BUILD_GRID — 3‑D locator grid\n",
    "\n",
    "| Key | Type | Default / Example | Purpose |\n",
    "|---|---|---|---|\n",
    "| `BOUNDARIES` | list [lon₁, lon₂, lat₁, lat₂, zmin, zmax] | [130.3, 131.8, 32.55, 33.5, 0, 25] | Geographic extents (°) and depth range (km) for the search grid. |\n",
    "| `SPACING_XYZ` | list [dx, dy, dz] (km) | [0.25, 0.25, 0.1] | Grid spacing along X (lon), Y (lat) and Z (depth). |\n",
    "| `CENTRE` | bool | False | If True, re‑centre grid so (0,0,0) sits at the geometric centre. |\n",
    "| `GRID_TAG` | string | 'heimdall_grid' | Key under which the grid is saved in the .npz file. |\n",
    "\n",
    "---\n",
    "\n",
    "## PREPARE_DATA — pre‑processing & label generation\n",
    "\n",
    "### DOWNSAMPLE\n",
    "\n",
    "| Key | Type | Default / Example | Purpose |\n",
    "|---|---|---|---|\n",
    "| `new_df` | float (Hz) | 100.0 | Target sampling rate after decimation. |\n",
    "| `hp_freq` | float (Hz) | 2 | High‑pass corner; the pipeline always applies a band‑pass from hp_freq to the new Nyquist. |\n",
    "\n",
    "### SOURCE_ERRORS_BY_PICKS\n",
    "\n",
    "Defines how much random error/noise to inject in the synthetic source label **based on how many P-picks / Event fall inside a window**.\n",
    "\n",
    "| n picks | [radius_km, max_noise, source_noise] | Meaning |\n",
    "|---|---|---|\n",
    "| 0–2 | [0, 0, 0] | No localisation information. |\n",
    "| 3 | [7, 0, 0] | If only 3 picks, smear the PDF within a 7 km radius. |\n",
    "| 4 | [6, 0, 0] | … |\n",
    "| 5 | [5, 0, 0] | … |\n",
    "| 6 | [4, 0, 0] | … |\n",
    "| 7 | [3, 0, 0] | … |\n",
    "| 8 | [2, 0, 0] | … |\n",
    "| 9 | [1, 0, 0] | … |\n",
    "| 10 | [0.7, 0, 0] | … |\n",
    "| 11 | [0.5, 0, 0] | With many picks the allowed radius keeps shrinking. |\n",
    "| >11 | last entry | Any higher pick count re‑uses the last line. |\n",
    "\n",
    "### SLICING\n",
    "\n",
    "| Key | Type | Default / Example | Purpose |\n",
    "|---|---|---|---|\n",
    "| `wlen_seconds` | float | 5.0 | Duration in seconds , adjust for your use-case (i.e. shorter for microseisms, longer for regional. Tips: calculate the distribution of S-P duration in your dataset and double it. |\n",
    "| `slide_seconds` | float | 0.5 | Rolling window's step (in seconds) between consecutive windows (`overlap = wlen − slide`). |\n",
    "\n",
    "---\n",
    "\n",
    "## TRAINING_PARAMETERS\n",
    "\n",
    "### PLOTS\n",
    "\n",
    "| Key | Type | Default / Example | Purpose |\n",
    "|---|---|---|---|\n",
    "| `make_plots` | bool | True | Enable the plotting routines for the test dataset (after training). For a quick view of training performances.|\n",
    "| `every_batches` | int | 50 | Draw a figure every N batches of the test-dataset. |\n",
    "\n",
    "### DATASET\n",
    "\n",
    "| Key | Type | Default / Example | Purpose |\n",
    "|---|---|---|---|\n",
    "| `how_many` | int or null | null | Cap the number of training elements (useful for quick tests). If null, takes all the H5 rows.|\n",
    "| `evenize` | dict | See below | Arguments passed to __evenize_classes__ that rebalance signal/noise windows. If `False` or `{}` all elements will be used.|\n",
    "| `batch_size` | int | 8 | Samples per mini‑batch sent to the model loader (i.e. DataLoader batching). |\n",
    "| `n_work` | int | 5 | PyTorch DataLoader workers (parallel file readers for faster I/O operations at training stage). Set the value to `(nproc/2)-1` available in your machine.|\n",
    "\n",
    "#### Evenize sub‑keys\n",
    "\n",
    "| Sub‑key | Default | Purpose |\n",
    "|---|---|---|\n",
    "| `min_pick_signal` | 1 | Minimum picks to call a window “signal”. |\n",
    "| `reduce_data` | False | If True, randomly drop part of the balanced set. |\n",
    "| `noise_perc` | 0.10 | Desired fraction of noise windows after balancing. |\n",
    "| `signal_perc` | 0.90 | Desired fraction of signal windows. |\n",
    "\n",
    "### AUGMENTATION\n",
    "\n",
    "| Key | Type | Default / Example | Purpose |\n",
    "|---|---|---|---|\n",
    "| `enabled` | bool | True | Toggles on‑the‑fly waveform augmentations (jitter, scaling, polarity flip …). |\n",
    "\n",
    "### RANDOM_SEED\n",
    "\n",
    "| Key | Type | Default / Example | Purpose |\n",
    "|---|---|---|---|\n",
    "| `RANDOM_SEED` | int | 42 | Seed for Python, NumPy and PyTorch to guarantee repeatable results. |\n",
    "\n",
    "### SPLIT\n",
    "\n",
    "| Key | Type | Default / Example | Purpose |\n",
    "|---|---|---|---|\n",
    "| `test` | float | 0.10 | Fraction of data set aside for the final test evaluation. |\n",
    "| `val` | float | 0.10 | Fraction used for early‑stopping / hyper‑parameter tuning. |\n",
    "\n",
    "### OPTIMISATION\n",
    "\n",
    "| Key | Type | Default / Example | Purpose |\n",
    "|---|---|---|---|\n",
    "| `learning_rate` | float | 1e‑4 | Initial LR for the Adam optimiser. |\n",
    "| `epochs` | int or null | null | Max epochs; null lets early‑stopping decide when to stop. |\n",
    "| `early_stopping.patience` | int | 7 | Non‑improving epochs to wait before halting. |\n",
    "| `early_stopping.delta` | float | 1e‑4 | Minimum drop in validation loss that counts as improvement. |\n",
    "\n",
    "### LOCATOR_LOSS\n",
    "\n",
    "| Key | Type | Default | Purpose |\n",
    "|---|---|---|---|\n",
    "| `xy` | float | 1.0 | Weight for XY plane pdf loss. |\n",
    "| `xz` | float | 1.0 | Weight for XZ plane pdf loss. |\n",
    "| `yz` | float | 1.0 | Weight for YZ plane pdf loss. |\n",
    "\n",
    "### COMPOSITE_LOSS\n",
    "\n",
    "| Key | Type | Default | Purpose |\n",
    "|---|---|---|---|\n",
    "| `alpha` | float | 1.0 | Weight for detector loss. |\n",
    "| `beta` | float | 1.0 | Weight for averaged locator‑plane loss. |\n",
    "| `gamma` | float | 1.0 | Weight for coordinate‑consistency loss. |\n",
    "\n",
    "### MODEL\n",
    "\n",
    "| Key | Type | Default / Example | Purpose |\n",
    "|---|---|---|---|\n",
    "| `pretrained_weights` | path / string | '' (empty) | Optional .pt file to warm‑start from; empty → train from scratch. |\n",
    "| `freeze_encoder` | bool | False | If True, the CNN encoder’s weights stay frozen (transfer‑learning). |\n",
    "\n",
    "---\n",
    "\n",
    "### Section pipeline summary\n",
    "\n",
    "1. BUILD_GNN & BUILD_GRID run once to create two .npz assets (heimdall_graph.npz, heimdall_grid.npz).\n",
    "2. PREPARE_DATA slices raw MiniSEED, injects label uncertainty and writes per‑event shards.\n",
    "3. HeimdallCore_2a_createHdf5.py merges shards; TRAINING_PARAMETERS then steer HeimdallCore_3_Training.py.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e16b27e-0cc2-4adf-87ff-0b996e306638",
   "metadata": {},
   "source": [
    "# Which uses what?\n",
    "\n",
    "Every `bin` uses mainly different parts:\n",
    "\n",
    "**core/**\n",
    "- `HeimdallCore_1_BuildNetwork.py`: uses `BUILD_GNN` sector\n",
    "- `HeimdallCore_1a_BuildGrid.py`: uses `BUILD_GRID` sector\n",
    "- `HeimdallCore_2_PrepareDataset.py`: uses `PREPARE_DATA` sector\n",
    "- `HeimdallCore_2a_createHdf5.py`: uses none\n",
    "- `HeimdallCore_3_Training.py`: uses `TRAINING_PARAMETERS` sector\n",
    "- `HeimdallCore_4_Predict.py`\n",
    "- `HeimdallCore_5_ExtractResults.py`\n",
    "\n",
    "**utils/**\n",
    "- `HeimdallUtils_Plot_Label.py`\n",
    "- `HeimdallUtils_Plot_Catalog.py`\n",
    "- `HeimdallUtils_Plot_Event.py`  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1575b0-3471-45e9-ac00-a39251f29f45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929cedb8-3b18-4611-9afb-76ea10e85297",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
